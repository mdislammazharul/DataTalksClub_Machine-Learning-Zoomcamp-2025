{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb1b3f0-91b9-4419-8ed9-30421f0c426f",
   "metadata": {},
   "source": [
    "### Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fba28f74-bf50-47c5-b287-9858e370aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ec997-0c1d-41c9-aed9-7f570668c676",
   "metadata": {},
   "source": [
    "### Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd44dff-5ea0-479c-9da8-72a8ba9f5334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0+cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2163be75-0f58-4d88-81a9-8e6eb5bb711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5414afcd-c70e-4913-8d0e-b3cf2ec9ef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 20073473\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db327cc1-20dd-4714-ad08-db2649c32cd7",
   "metadata": {},
   "source": [
    "### Seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "781de76d-5f08-405e-aec3-ebba4f3ee503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40daa09f-4aed-4576-aef5-952408341168",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b951956c-f1e1-4a39-80dd-ffc3ff0a423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4046fa3-b20c-4ee1-9528-893518b6ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train'\n",
    "test_dir = 'data/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86794327-c83d-4180-b16f-05bb3e0eb020",
   "metadata": {},
   "source": [
    "### Model\n",
    "For this homework we will use Convolutional Neural Network (CNN). We'll use PyTorch.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "The shape for input should be (3, 200, 200) (channels first format in PyTorch)\\\n",
    "Next, create a convolutional layer (nn.Conv2d):\\\n",
    "Use 32 filters (output channels)\\\n",
    "Kernel size should be (3, 3) (that's the size of the filter)\\\n",
    "Use 'relu' as activation\\\n",
    "Reduce the size of the feature map with max pooling (nn.MaxPool2d)\\\n",
    "Set the pooling size to (2, 2)\\\n",
    "Turn the multi-dimensional result into vectors using flatten or view\\\n",
    "Next, add a nn.Linear layer with 64 neurons and 'relu' activation\\\n",
    "Finally, create the nn.Linear layer with 1 neuron - this will be the output\\\n",
    "The output layer should have an activation - use the appropriate activation for the binary classification case\\\n",
    "As optimizer use torch.optim.SGD with the following parameters:\\\n",
    "\n",
    "torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84caadb0-d36f-48db-8942-0f3446e6084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use padding=1 to preserve spatial dims before pooling\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # 200x200 -> 200x200\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)                           # -> 100x100\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # 100x100 -> 100x100\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        # -> after pool -> 50x50\n",
    "\n",
    "        # Reduce final spatial map with adaptive pooling to a small fixed size\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))  # yields 64 x 4 x 4 => 1024 features\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 64)\n",
    "        self.dropout = nn.Dropout(p=0.4)   # help generalization\n",
    "        self.fc2 = nn.Linear(64, 1)        # logits output (no sigmoid here)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc2(x)\n",
    "        return logits  # return raw logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "836ee64b-6a3d-4ff3-a0b1-61a810b011e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNBinaryClassifier(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (adaptive_pool): AdaptiveAvgPool2d(output_size=(4, 4))\n",
      "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate model once and move to device\n",
    "model = CNNBinaryClassifier().to(device)\n",
    "print(model)\n",
    "\n",
    "# criterion and optimizer as required\n",
    "criterion = nn.BCEWithLogitsLoss()  # stable: combines sigmoid+BCEloss internally\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
    "\n",
    "# Data transforms (base, no augmentation yet)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "val_transforms = train_transforms\n",
    "\n",
    "# dataset paths (adjust if different)\n",
    "train_dir = 'data/train'\n",
    "test_dir  = 'data/test'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
    "validation_dataset = datasets.ImageFolder(root=test_dir, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a29f94f-aa67-44bf-a152-8287d3ac9b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10  Loss: 0.6700  Acc: 0.5575  Val Loss: 0.6561  Val Acc: 0.7015\n",
      "Epoch 2/10  Loss: 0.6150  Acc: 0.7100  Val Loss: 0.6095  Val Acc: 0.7114\n",
      "Epoch 3/10  Loss: 0.5634  Acc: 0.7475  Val Loss: 0.5574  Val Acc: 0.7313\n",
      "Epoch 4/10  Loss: 0.5180  Acc: 0.7725  Val Loss: 0.5515  Val Acc: 0.7711\n",
      "Epoch 5/10  Loss: 0.4983  Acc: 0.7837  Val Loss: 0.5291  Val Acc: 0.7711\n",
      "Epoch 6/10  Loss: 0.4795  Acc: 0.7975  Val Loss: 0.5190  Val Acc: 0.7562\n",
      "Epoch 7/10  Loss: 0.4607  Acc: 0.8063  Val Loss: 0.5104  Val Acc: 0.7711\n",
      "Epoch 8/10  Loss: 0.4316  Acc: 0.8100  Val Loss: 0.5226  Val Acc: 0.7562\n",
      "Epoch 9/10  Loss: 0.4407  Acc: 0.8125  Val Loss: 0.5573  Val Acc: 0.7214\n",
      "Epoch 10/10  Loss: 0.4320  Acc: 0.8213  Val Loss: 0.4864  Val Acc: 0.7711\n"
     ]
    }
   ],
   "source": [
    "# training loop - record history\n",
    "num_epochs = 10\n",
    "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)  # shape (B,1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)           # logits shape (B,1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        # compute predicted labels from logits\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        predicted = (probs > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predicted = (probs > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}  Loss: {epoch_loss:.4f}  Acc: {epoch_acc:.4f}  Val Loss: {val_epoch_loss:.4f}  Val Acc: {val_epoch_acc:.4f}\")\n",
    "\n",
    "# After training you can save:\n",
    "torch.save(model.state_dict(), \"cnn_binary_fixed.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce67ad1c-29c0-4233-a314-a101e905c0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median training accuracy: 0.7906249999999999\n"
     ]
    }
   ],
   "source": [
    "median_acc = statistics.median(history['acc'])\n",
    "print(\"Median training accuracy:\", median_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "111d0abc-df50-43ae-b499-3ccdfff592f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of training loss: 0.0817053844190638\n"
     ]
    }
   ],
   "source": [
    "train_losses = history['loss']\n",
    "std_loss = statistics.stdev(train_losses)\n",
    "\n",
    "print(\"Standard deviation of training loss:\", std_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05df4b8d-c2e3-4324-a6f4-c7f92ba61b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AUG] Epoch 1/10  Loss: 0.5073  Acc: 0.7750  Val Loss: 0.4694  Val Acc: 0.7811\n",
      "[AUG] Epoch 2/10  Loss: 0.4956  Acc: 0.7688  Val Loss: 0.4457  Val Acc: 0.8010\n",
      "[AUG] Epoch 3/10  Loss: 0.4711  Acc: 0.7863  Val Loss: 0.4724  Val Acc: 0.7861\n",
      "[AUG] Epoch 4/10  Loss: 0.4811  Acc: 0.7863  Val Loss: 0.4429  Val Acc: 0.8010\n",
      "[AUG] Epoch 5/10  Loss: 0.4755  Acc: 0.7650  Val Loss: 0.4530  Val Acc: 0.7960\n",
      "[AUG] Epoch 6/10  Loss: 0.4698  Acc: 0.7950  Val Loss: 0.4474  Val Acc: 0.7662\n",
      "[AUG] Epoch 7/10  Loss: 0.4544  Acc: 0.7887  Val Loss: 0.5863  Val Acc: 0.7363\n",
      "[AUG] Epoch 8/10  Loss: 0.4711  Acc: 0.7963  Val Loss: 0.5214  Val Acc: 0.7363\n",
      "[AUG] Epoch 9/10  Loss: 0.4588  Acc: 0.8025  Val Loss: 0.4197  Val Acc: 0.7960\n",
      "[AUG] Epoch 10/10  Loss: 0.4499  Acc: 0.7975  Val Loss: 0.4936  Val Acc: 0.7562\n",
      "Mean test (val) loss over all recorded epochs: 0.512553000924599\n",
      "Average val accuracy for last 5 epochs of augmentation block: 0.7582089552238805\n"
     ]
    }
   ],
   "source": [
    "# Augmented train transforms (as requested)\n",
    "aug_train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.RandomRotation(50),\n",
    "    transforms.RandomResizedCrop(200, scale=(0.9,1.0), ratio=(0.9,1.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# Replace the train dataset and loader (keep the same model and optimizer)\n",
    "train_dataset.transform = aug_train_transforms\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "# Continue training for 10 more epochs\n",
    "num_more_epochs = 10\n",
    "# We'll append new history entries; keep previous history if needed\n",
    "for epoch in range(num_more_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        predicted = (probs > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    # validation (test) step\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predicted = (probs > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(f\"[AUG] Epoch {epoch+1}/{num_more_epochs}  Loss: {epoch_loss:.4f}  Acc: {epoch_acc:.4f}  Val Loss: {val_epoch_loss:.4f}  Val Acc: {val_epoch_acc:.4f}\")\n",
    "\n",
    "# After training, metrics for Q5 and Q6:\n",
    "\n",
    "# Q5: mean of test loss for all epochs (the new 'val_loss' array contains the \n",
    "#      losses for the validation set for ALL epochs including previous ones and the newly added ones).\n",
    "import numpy as np\n",
    "mean_test_loss_all_epochs = float(np.mean(history['val_loss']))\n",
    "print(\"Mean test (val) loss over all recorded epochs:\", mean_test_loss_all_epochs)\n",
    "\n",
    "# Q6: average of test accuracy for the last 5 epochs (from 6 to 10 of the *augmentation training session*).\n",
    "# If you continued for 10 more epochs, those are the last 10 appended items in history['val_acc'].\n",
    "# To get last-5 of the augmentation block, do:\n",
    "aug_block_val_acc = history['val_acc'][-10:]   # last 10 epochs (augmentation block)\n",
    "avg_last5_aug = float(np.mean(aug_block_val_acc[-5:]))\n",
    "print(\"Average val accuracy for last 5 epochs of augmentation block:\", avg_last5_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75d3102-8a9f-4fa0-ba6f-0d84be039366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
